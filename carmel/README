/*******************************************************************************
* This software ("Carmel") is licensed for research use only, as described in  *
* the LICENSE file in this distribution.  The software can be downloaded from  *
* http://www.isi.edu/natural-language/licenses/carmel-license.html.  Please    *
* contact Kevin Knight (knight@isi.edu)    *
* with questions about the software or commercial licensing.  All software is  *
* copyrighted C 2000 by the University of Southern California.                 *
*******************************************************************************/

note: carmel/src/config.hpp currently has USE_OPENFST defined.  to build, either
undefine it, or extract http://www.openfst.org so that the directory "fst"
(containing "fst/lib") is a sibling of "graehl" (or ensure that "fst" is in your
include path)

openfst is used to allow determinization/minimization


Carmel Version 3.2:

This version of carmel is released on 2007-06-20. For changes and
additions to Carmel, see ChangeLog.

Table of Contents:
--------------------
	I	What's In This Distribution:
	II	Installation:
	III	Compiling Carmel:
	IV	Carmel File Formats:
	V	Running Carmel:
--------------------------------------------------------------------------------
Part I: What's In This Distribution:
-------------------------------------
The distribution (after being installed - see Part II for details)
includes the following directories and files:

	src/	include the C++ source files
	doc/	include the documentation files (FORMATS + tutorial).
	bin/	Carmel executables.
	sample/	The examples for Carmel tutorial. The tutorial can be
		found  in the doc/ directory.
	LICENSE	The license agreement for this software.
	README	This file.


Part II: Installation:
----------------------

1. Rename the file carmel-tar-gz.pl as carmel.tar.gz (% mv carmel-tar-gz.pl carmel.tar.gz)

2. Gunzip the software (% gunzip carmel.tar.gz)

3. Un-tar the software (% tar -xvf carmel.tar).

This should create the main directory structure for carmel.

Part III: Compiling Carmel:
----------------------------

Carmel now requires GCC version 3 to compile.  You can download the source to GCC
and install it into your home directory, and use it to compile carmel by editing the Makefile.

A Makefile  is included in this distribution. The Makefile can be
found in the main carmel directory. Follow these steps for
installation:

1. create an empty file in the main carmel directory and call that
file dependencies.ARCH

ARCH may be:
solaris
cygwin
linux
freebsd

(or others you create by editing the Makefile)

you may need to set CC.$ARCH to point to your version 3 or greater g++
(on some systems it will be called g++30 or similar)


You should probably use GNU make (3.8 or later)

2. Create the dependency structure, to do that type:

   % make depend

3. Compile carmel

   % make 

Carmel also compiles with the latest Microsoft Visual C++ (.NET currently).
A project file is included in the msvc++ directory.  *This hasn't been checked lately!*

Part IV: Carmel File Formats:
------------------------------

The input file formats for Carmel are explained in the file FORMATS in
the documentation directory doc/ .

Part V: Running Carmel:
------------------------
Carmel take its options on the command line. The list of valid options
can be obtained by typing "carmel" with no command line options.
The valid options are explained below:


usage: carmel [switches] [file1 file2 ... filen]

composes a sequence of weighted finite state transducers and writes the
result to the standard output.

-l (default)	left associative composition ((file1*file2) * file3 ... )
-r		right associative composition (file1 * (file2*file3) ... )
-s		the standard input is prepended to the sequence of files (for
		left associative composition), or appended (if right
		associative)
-i		the first input (depending on associativity) is interpreted as
		a space-separated sequence of symbols, and translated into a
		transducer accepting only that sequence
-P Similar to (-i) but instead of building an acceptor with a
		single arc, construct a permutaion lattice that accepts the
		input in all possible reorderings.
-k n		the n best paths through the resulting transducer are written
		to the standard output in lieu of the transducer itself
-b		batch compostion - reads the sequence of transducers into
		memory, except the first input (depending on associativity),
		which consists of sequences of space-separated input symbols
		(as in -i) separated by newlines.  The best path(s) through
		the result of each composition are written to the standard
		output, one per line, in the same order as the inputs that
		generated them
-S		as in -b, the input (file or stdin) is a newline separated
		list of symbol sequences, except that now the odd lines are
		input sequences, with the subsequent sequence being the
		corresponding output sequence
		this command scores the input / output pairs by adding the sum
		of the weights of all possible paths producing them, printing
		the weights one per line if -i is used, it will apply to the
		second input, as -i consumes the first
-n		normalize the weights of arcs so that for each state, the
		weights all of the arcs with the same input symbol add to one
-t		given pairs of input/output sequences, as in -S, adjust the
		weights of the transducer so as to approximate the conditional
		distribution of the output sequences given the input sequences
		optionally, an extra line preceeding an input/output pair may
		contain a floating point number for how many times the 
		input/output pair should count in training (default is 1)
-e w		w is the convergence criteria for training (the minimum
		change in an arc's weight to trigger another iteration) - 
		default w is 1E-4 (or, -4log)
-X w		w is a perplexity convergence ratio between 0 and 1,
		with 1 being the strictest (default w=.999)
-f w		w is a per-training example floor weight used for training,
		added to the counts for all arcs, immediately before normalization -
		(this implements so-called "Dirichlet prior" smoothing)
-U		use the initial weights of non-locked arcs as per-example prior counts
		(in the same way as, and in addition to, -f)
-M n		n is the maximum number of training iterations that will be
		performed, regardless of whether the convergence criteria is
		met - default n is 256
-x		list only the input alphabet of the transducer to stdout
-y		list only the output alphabet of the transducer to stdout
-c		list only statistics on the transducer to stdout
-F filename	write the final transducer to a file (in lieu of stdout)
-v		invert the resulting transducer by swapping the input and
		output symbols 
-d		do not reduce (eliminate dead-end states) created
-C		consolidate arcs with same source, destination, input and
		output, with a total weight equal to the sum (clamped to a
		maximum weight of one)
-p w		prune (discard) all arcs with weight less than w
-w w		prune states and arcs only used in paths w times worse
		than the best path (1 means keep only best path, 10 = keep paths up to 10 times weaker)
-z n		keep at most n states (those used in highest-scoring paths)
-G n		stochastically generate n input/output pairs by following
		random paths (first choosing an input symbol with uniform
		probability, then using the weights to choose an output symbol
		and destination) from the initial state to the final state
		output is in the same form accepted in -t and -S.
		Training a transducer with conditional normalization on its own -G output should be a no-op.
-g n		stochastically generate n paths by randomly picking an arc
		leaving the current state, by joint normalization
		until the final state is reached.
		same output format as -k best paths

-@		For -G or -k, output in the same format as -g and -t.  training on this output with joint normalization should then be a noop.
-R n		Use n as the random seed for repeatable -g and -G results
		default seed = current time
-L n		while generating input/output pairs with -g or -G, give up if
		final state isn't reached after n steps (default n=1000)
-T n		during composition, index arcs in a hash table when the
		product of the number of arcs of two states is greater than n 
		(by default, n = 32)
-N n		assign each arc in the result transducer a unique group number
		starting at n and counting up.  If n is 0 (the special group
		for unchangeable arcs), all the arcs are assigned to group 0
		if n is negative, all group numbers are removed
-j		Perform joint rather than conditional normalization
-A		the weights in the first transducer (depending on -l or -r, as
		with -b, -S, and -t) are assigned to the result, by arc group
		number.  Arcs with group numbers for which there is no
		corresponding group in the first transducer are removed
-m		give meaningful names to states created in composition
		rather than just numbers
-a		during composition, keep the identity of matching arcs from
		the two transducers separate, assigning the same arc group
		number to arcs in the result as the arc in the transducer it
		came from.  This will create more states, and possibly less
		arcs, than the normal approach, but the transducer will have
		equivalent paths.
-h		help on transducers, file formats
-V		version number
-u		Don't normalize outgoing arcs for each input during training;
		try -tuM 1 to see forward-backward counts for arcs
-Y		Write transducer to GraphViz .dot file
		(see http://www.research.att.com/sw/tools/graphviz/)
-q		Suppress computation status messages (quiet!)
-K		Assume state names are integer indexes (when the final state is an integer)
-o g		Use learning rate growth factor g (>= 1) (default=1)
-1		randomly scale weights (of unlocked arcs) after composition uniformly by (0..1]
-! n		perform n additional random initializations of arcs for training, keeping the lowest perplexity

some formatting switches for paths from -k or -G:
	-I	show input symbols only
	-O	show output symbols only
	-E	if -I or -O is specified, omit special symbols (beginning and
		ending with an asterisk (e.g. "*e*"))
	-Q	if -I or -O is specified, omit outermost quotes of symbol names
	-W	do not show weights for paths

Weight output format switches
		(by default, small/large weights are written as logarithms):
	-Z	Write weights in logarithm form always, e.g. 'e^-10',
		except for 0, which is written simply as '0'
	-B	Write weights as their base 10 log (e.g. -1log == 0.1)
	-2	Instead of e^K, output Kln (deprecated)
	-D	Write weights as reals always, e.g. '1.234e-200'

Transducer output format switches:
	-H	One arc per line (by default one state and all its arcs per line)
	-J	Don't omit output=input or Weight=1

Confused?  Think you've found a bug?  If all else fails, e-mail graehl@isi.edu or knight@isi.edu
