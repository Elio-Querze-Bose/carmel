#!/bin/bash
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-/scratch/hadoop/conf}
BLOBS=${BLOBS:-~graehl/blobs}
. $BLOBS/bashlib/unstable/bashlib.sh

#hadfs() {
#    $d/fhadoop "$@"
#}

hadrmf() {
    local in=$1
    if hadexists "$in" ; then
        if [ "$noclobber" ] ;then
            error HDFS: $in already exists
        else
            echo2 HDFS: removing existing $in
            hadfs -rmr "$in"
        fi
    fi
}

usage() {
    cat<<EOF
    usage: [local=1 [savemap=map.output]] [noclobber=1] [file=file-cp-to-wd] [combine=1] $0 in out map reduce [hadoop args]
    in and out should be dir-less filenames or '-' for stdin/stdout (local only)
EOF
    exit 1
}

filex() {
    local map=$1
    local wmap=`which $map`
    [[ -x $wmap ]] && files+=" $wmap"
}

realx() {
    local map=$1
    shift
    if [[ -x $map ]] ; then
        false
    else
        local wmap=$(rwhich $map)
        [[ $wmap != $map ]] && echo2 resolved $map to $wmap for hadoop.
        xcmd="$wmap $@"
        [[ $wmap != $map ]]
    fi
}

main() {
  set -e
  local in=$1
  [[ $in ]] || usage
  local out=$2
  local map=$3
  local reduce=$4
  shift
  shift
  shift
  shift
  showvars_required in out map
  if [[ ! $reduce ]] ; then
      reduce=NONE
  fi

  showvars_optional local file combine buflines stage noclobber infs outfs
  showvars_required in out map reduce

  files=$file
  if [ "$stage" ] ; then
      filex $map || true
      filex $reduce || true
  else
      if realx $map ; then map=$xcmd ; fi
      if realx $reduce ; then reduce=$xcmd ; fi
  fi
  showvars_optional file
  for f in $files ; do
      filearg+=" -file \"$f\""
      showvars_required f filearg
  done

  [[ $combine ]] && map="sh -c '$map | $d/precombine.py -b ${buflines:=100000} | $reduce'"

  if [[ $local ]] ; then
      if [[ $infs ]] ; then cp "$infs" "$in"; fi
      previewf "$in"
      echo2 "catz $in | $map | mapsort | $reduce | catz_to $out"
      echo2
      catz "$in" | $map | mapsort | $reduce | catz_to "$out"
      if [[ $outfs ]] ; then  cp "$out" "$outfs"; fi
      previewf "$out"
  else
      [[ $in = - ]] && in="stdin.`nanotime`" && $infs=-
      if [[ $infs ]] ; then
          hadrmf "$in"
          hadfs -put "$infs" "$in"
      elif ! hadexists "$in" ; then
          require_file "$in"
          echo2 using implicit infs=$in - copying local file to hadoop
          hadfs -put "$in" "$in"
      fi
      [[ $out = - ]] && out="stdout.`nanotime`" && outfs=-
      hadrmf "$out"
      hadpreview "$in"
      set -x
      $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/contrib/streaming/hadoop-streaming.jar \
          -input "$in" -output "$out" -mapper "$map" -reducer "$reduce" $filearg "$@"
      set +x
      echo2
      hadpreview "$out"
      [[ $outfs ]] && hadcat "$out" | catz_to "$outfs"
  fi
}
main "$@"
